import eventlet
eventlet.monkey_patch()  # âš ï¸ Gá»i sá»›m nháº¥t

import os
import json
import numpy as np
import joblib
import traceback
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit
from tensorflow.keras.models import load_model
from collections import deque

# Buffer Ä‘á»ƒ lÆ°u dá»¯ liá»‡u cáº£m biáº¿n (window_size = 6)
sensor_buffer = deque(maxlen=6)

# --- Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n (cáº­p nháº­t theo tÃªn file tá»« training code) ---
MODEL_PATH = './env_model.h5'
FEATURE_SCALER_PATH = './env_feature_scaler.pkl'
TARGET_SCALER_PATH = './env_target_scaler.pkl'

# --- Khá»Ÿi táº¡o Flask App ---
app = Flask(__name__, template_folder='templates')
app.config['SECRET_KEY'] = 'secret_key'

# --- Cáº¥u hÃ¬nh SocketIO ---
socketio = SocketIO(
    app,
    cors_allowed_origins="*",
    async_mode='eventlet',
    logger=True,
    engineio_logger=True,
    ping_timeout=60,
    ping_interval=25,
    allow_upgrades=True,
    websocket=True
)

# --- Load mÃ´ hÃ¬nh vÃ  scaler ---
print("ğŸ”„ Äang load mÃ´ hÃ¬nh vÃ  scaler...")
try:
    model = load_model(MODEL_PATH, compile=False)
    feature_scaler = joblib.load(FEATURE_SCALER_PATH)
    target_scaler = joblib.load(TARGET_SCALER_PATH)
    print("âœ… ÄÃ£ load thÃ nh cÃ´ng.")
    print(f"ğŸ“Š Input shape mÃ´ hÃ¬nh: {model.input_shape}")
    print(f"ğŸ“Š Output shape mÃ´ hÃ¬nh: {model.output_shape}")
except Exception as e:
    print("âŒ Lá»—i khi load mÃ´ hÃ¬nh hoáº·c scaler:", e)
    traceback.print_exc()
    exit()

# --- Route tráº£ vá» giao diá»‡n chÃ­nh ---
@app.route('/')
def index():
    return render_template('index.html')

# --- Sá»± kiá»‡n khi client káº¿t ná»‘i ---
@socketio.on('connect')
def handle_connect():
    sid = request.sid
    print(f"ğŸ“¡ Client connected! SID: {sid}")
    emit('connect_response', {'status': 'connected'})

@socketio.on('disconnect')
def handle_disconnect():
    sid = request.sid
    print(f"ğŸ”Œ Client disconnected! SID: {sid}")

# --- HÃ m xÃ¡c Ä‘á»‹nh status dá»±a trÃªn giÃ¡ trá»‹ ---
def determine_status_from_values(temp, humidity):
    """
    XÃ¡c Ä‘á»‹nh status dá»±a trÃªn giÃ¡ trá»‹ nhiá»‡t Ä‘á»™ vÃ  Ä‘á»™ áº©m
    Báº¡n cÃ³ thá»ƒ tÃ¹y chá»‰nh logic nÃ y theo yÃªu cáº§u thá»±c táº¿
    """
    if temp < 15 or temp > 35 or humidity < 30 or humidity > 80:
        return 'critical'
    elif temp < 20 or temp > 30 or humidity < 40 or humidity > 70:
        return 'warning'
    else:
        return 'normal'

# --- HÃ m dá»± Ä‘oÃ¡n giÃ¡ trá»‹ tiáº¿p theo ---
def predict_next_values(model, scaler, target_scaler, last_sequence):
    """
    Predict next temperature and humidity values
    
    Args:
        model: trained model
        scaler: fitted feature scaler
        target_scaler: fitted target scaler  
        last_sequence: array of shape (window_size, 2) with last 6 [temp, humidity] pairs
    
    Returns:
        predicted [temperature, humidity] in original scale
    """
    try:
        # Normalize the input
        last_sequence_scaled = scaler.transform(last_sequence)
        
        # Reshape for model input: (1, window_size, 2)
        last_sequence_scaled = last_sequence_scaled.reshape(1, 6, 2)
        
        # Make prediction
        pred_scaled = model.predict(last_sequence_scaled, verbose=0)
        
        # Convert back to original scale
        pred_original = target_scaler.inverse_transform(pred_scaled)
        
        return pred_original[0]
    except Exception as e:
        print(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh dá»± Ä‘oÃ¡n: {e}")
        traceback.print_exc()
        return None

# --- Nháº­n dá»¯ liá»‡u cáº£m biáº¿n tá»« ESP32 ---
@socketio.on('sensor_data')
def handle_sensor_data(data):
    global sensor_buffer
    try:
        print("ğŸ“¥ Dá»¯ liá»‡u nháº­n Ä‘Æ°á»£c:", data)

        if isinstance(data, str):
            sensor_values = json.loads(data)
        else:
            sensor_values = data

        # Kiá»ƒm tra Ä‘á»‹nh dáº¡ng dá»¯ liá»‡u
        # Dá»± kiáº¿n: [temperature, humidity]
        if not isinstance(sensor_values, list) or len(sensor_values) < 2:
            emit('error', {'message': 'Dá»¯ liá»‡u pháº£i lÃ  máº£ng chá»©a 2 giÃ¡ trá»‹ [temperature, humidity]'})
            return

        # Láº¥y temperature vÃ  humidity
        env_temp = float(sensor_values[0])
        env_humi = float(sensor_values[1])
        
        # Táº¡o feature vector chá»‰ gá»“m 2 giÃ¡ trá»‹: [env_temp, env_humi]
        feature_vector = [env_temp, env_humi]
        
        # ThÃªm vÃ o buffer
        sensor_buffer.append(feature_vector)
        
        # XÃ¡c Ä‘á»‹nh status hiá»‡n táº¡i
        current_status = determine_status_from_values(env_temp, env_humi)

        # Táº¡o dá»¯ liá»‡u Ä‘á»ƒ gá»­i vá» dashboard
        dashboard_data = {
            'temperature': env_temp,
            'humidity': env_humi,
            'status': current_status,
            'buffer_size': len(sensor_buffer)
        }

        # PhÃ¡t láº¡i dá»¯ liá»‡u Ä‘á»ƒ hiá»ƒn thá»‹ dashboard
        socketio.emit('sensor_data_received', dashboard_data)

        # Kiá»ƒm tra xem Ä‘Ã£ Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ dá»± Ä‘oÃ¡n chÆ°a
        if len(sensor_buffer) < 6:
            print(f"ğŸ• ÄÃ£ nháº­n {len(sensor_buffer)}/6 máº«u. ChÆ°a Ä‘á»§ Ä‘á»ƒ dá»± Ä‘oÃ¡n.")
            return

        # Chuáº©n bá»‹ dá»¯ liá»‡u cho dá»± Ä‘oÃ¡n
        recent_data = np.array(sensor_buffer)
        print(f"ğŸ“Š HÃ¬nh dáº¡ng dá»¯ liá»‡u buffer: {recent_data.shape}")

        # Kiá»ƒm tra shape Ä‘Ãºng (6, 2)
        if recent_data.shape != (6, 2):
            print(f"âŒ Shape khÃ´ng Ä‘Ãºng. Mong Ä‘á»£i (6, 2), nháº­n Ä‘Æ°á»£c {recent_data.shape}")
            return

        # Dá»± Ä‘oÃ¡n giÃ¡ trá»‹ tiáº¿p theo
        prediction = predict_next_values(model, feature_scaler, target_scaler, recent_data)
        
        if prediction is None:
            emit('error', {'message': 'Lá»—i trong quÃ¡ trÃ¬nh dá»± Ä‘oÃ¡n'})
            return

        # Chuáº©n bá»‹ response
        predicted_temp = round(float(prediction[0]), 2)
        predicted_humi = round(float(prediction[1]), 2)
        
        # XÃ¡c Ä‘á»‹nh status dá»± Ä‘oÃ¡n
        predicted_status = determine_status_from_values(predicted_temp, predicted_humi)

        response = {
            'predicted_temperature': predicted_temp,
            'predicted_humidity': predicted_humi,
            'predicted_status': predicted_status,
            'current_temperature': env_temp,
            'current_humidity': env_humi,
            'current_status': current_status,
            'timestamp': len(sensor_buffer),
            'buffer_data': [{'temp': round(row[0], 2), 'humi': round(row[1], 2)} for row in sensor_buffer]
        }

        print("ğŸ“¤ Gá»­i dá»± Ä‘oÃ¡n:", response)
        socketio.emit('prediction', response)

    except Exception as e:
        print("âŒ Lá»—i xá»­ lÃ½ dá»¯ liá»‡u:", e)
        traceback.print_exc()
        emit('error', {'message': f'Lá»—i xá»­ lÃ½: {str(e)}'})

# --- API endpoint Ä‘á»ƒ reset buffer ---
@socketio.on('reset_buffer')
def handle_reset_buffer():
    global sensor_buffer
    sensor_buffer.clear()
    print("ğŸ”„ Buffer Ä‘Ã£ Ä‘Æ°á»£c reset")
    emit('buffer_reset', {'status': 'success', 'message': 'Buffer Ä‘Ã£ Ä‘Æ°á»£c reset'})

# --- API endpoint Ä‘á»ƒ láº¥y thÃ´ng tin mÃ´ hÃ¬nh ---
@socketio.on('get_model_info')
def handle_get_model_info():
    try:
        model_info = {
            'input_shape': model.input_shape,
            'output_shape': model.output_shape,
            'buffer_size': len(sensor_buffer),
            'max_buffer_size': sensor_buffer.maxlen,
            'features': ['temperature', 'humidity'],
            'targets': ['temperature', 'humidity'],
            'window_size': 6
        }
        emit('model_info', model_info)
    except Exception as e:
        emit('error', {'message': f'Lá»—i láº¥y thÃ´ng tin mÃ´ hÃ¬nh: {str(e)}'})

# --- Test endpoint Ä‘á»ƒ gá»­i dá»¯ liá»‡u giáº£ ---
@socketio.on('test_data')
def handle_test_data():
    """
    Gá»­i dá»¯ liá»‡u test Ä‘á»ƒ kiá»ƒm tra há»‡ thá»‘ng
    """
    import random
    
    # Táº¡o dá»¯ liá»‡u test
    test_temp = round(random.uniform(20, 30), 2)
    test_humi = round(random.uniform(50, 70), 2)
    test_data = [test_temp, test_humi]
    
    print(f"ğŸ§ª Gá»­i dá»¯ liá»‡u test: {test_data}")
    handle_sensor_data(test_data)

# --- Test endpoint Ä‘á»ƒ gá»­i nhiá»u dá»¯ liá»‡u test ---
@socketio.on('test_multiple_data')
def handle_test_multiple_data():
    """
    Gá»­i nhiá»u dá»¯ liá»‡u test Ä‘á»ƒ Ä‘á»§ buffer cho dá»± Ä‘oÃ¡n
    """
    import random
    import time
    
    print("ğŸ§ª Gá»­i 6 máº«u dá»¯ liá»‡u test Ä‘á»ƒ kiá»ƒm tra dá»± Ä‘oÃ¡n...")
    
    for i in range(6):
        test_temp = round(random.uniform(20, 30), 2)
        test_humi = round(random.uniform(50, 70), 2)
        test_data = [test_temp, test_humi]
        
        print(f"ğŸ§ª Máº«u {i+1}/6: {test_data}")
        handle_sensor_data(test_data)
        
        # Nhá» delay Ä‘á»ƒ tháº¥y rÃµ quÃ¡ trÃ¬nh
        eventlet.sleep(0.1)

# --- API endpoint Ä‘á»ƒ láº¥y buffer hiá»‡n táº¡i ---
@socketio.on('get_buffer')
def handle_get_buffer():
    try:
        buffer_data = {
            'buffer': [{'temp': round(row[0], 2), 'humi': round(row[1], 2)} for row in sensor_buffer],
            'size': len(sensor_buffer),
            'max_size': sensor_buffer.maxlen,
            'ready_for_prediction': len(sensor_buffer) >= 6
        }
        emit('buffer_data', buffer_data)
    except Exception as e:
        emit('error', {'message': f'Lá»—i láº¥y buffer: {str(e)}'})

# --- Khá»Ÿi Ä‘á»™ng server ---
if __name__ == '__main__':
    print("=" * 60)
    print("--- ğŸš€ Environment Monitoring Server Ä‘ang khá»Ÿi Ä‘á»™ng ---")
    print(f"ğŸ”§ Cháº¿ Ä‘á»™ async: {socketio.async_mode}")
    print(f"ğŸ“ Model path: {MODEL_PATH}")
    print(f"ğŸ“ Feature scaler: {FEATURE_SCALER_PATH}")
    print(f"ğŸ“ Target scaler: {TARGET_SCALER_PATH}")
    print(f"ğŸ“Š Buffer size: {sensor_buffer.maxlen}")
    print(f"ğŸ“Š Input features: Temperature, Humidity")
    print(f"ğŸ“Š Output targets: Temperature, Humidity")
    print("=" * 60)
    socketio.run(app, host='0.0.0.0', port=5000, debug=True, use_reloader=False, allow_unsafe_werkzeug=True)